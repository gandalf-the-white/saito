#+title: Readme
* Introduction
Just to prove that we can use practice *LLM* with *LISP*. 
The agent is composed of different stacks:
+ Client (run-weather-agent)
+ Ollama Client
+ Ollama / LLM
+ Tool Manager
+ Tool Manager

* Explication
** Client (run-weather-agent)
+ Receives the user's question.
+ Builds the initial message with the system prompt.
+ Launches the orchestration loop.
** Ollama Client
+ Encodes messages in JSON.
+ Sends the request to Ollama via HTTP POST (/api/chat).
+ Receives a JSON response.
** Ollama / LLM
+ Produces either:
  + a normal response,
  + a native tool_call,
  + or a fake JSON tool call in the content field.
** Tool Manager
 + Groups all saved tools.
 + Finds the right tool to call, either:
 + via tool_calls,
 + via manual JSON found in content.
** Tools
Each tool is an independent module with:
+ a JSON schema
+ a Lisp handler
+ an entry in the *tools* list
** Example
+ get_time
+ get_weather
** External APIs
The tools can call:
+ Open-Meteo (geocoding + weather)
+ The system time, etc.
** Call Flow (Summary)
1. The user sends a question to run-weather-agent.
2. The agent adds the system prompt and messages.
3. The messages are sent to Ollama.
4. The model responds:
   a. either with a tool_call
   b. or with manual JSON
   c. or with a classic response.
5. If a tool is detected:
   1. The Tool Manager calls the tool handler.
   2. The handler returns a structured response.
6. The final result is returned to the user.

* Graphic
** Flow Diagram
#+begin_src plantuml :file ./images/diagram.svg :results silent :exports none
@startuml WeatherAgentSequence

actor Utilisateur
participant "Agent LISP\n(saito)" as agent
participant "Ollama\n(llama3.2)" as ollama
participant "Open-Meteo\n(Geocoding)" as geocoding
participant "Open-Meteo\n(Forecast)" as forecast

Utilisateur -> agent: "Peux-tu me donner\la météo actuelle à Paris ?"
activate agent

agent -> ollama: call-ollama(messages)
activate ollama
ollama --> agent: réponse avec tool_call\n("get_weather", {"city": "Paris"})
deactivate ollama

agent -> agent: handle-tool-call\n(exécute get_weather)
activate agent
agent -> geocoding: geocode-city("Paris")
activate geocoding
geocoding --> agent: (lat, lon, name, country, admin1, timezone)
deactivate geocoding

agent -> forecast: http-request(forecast?lat=...&lon=...)
activate forecast
forecast --> agent: {current_weather: {...}}
deactivate forecast

agent -> agent: formatte la réponse météo
agent -> ollama: envoie le résultat du tool\n(role: "tool", content: "Météo pour Paris...")
activate ollama
ollama --> agent: réponse finale\n("Météo pour Paris : 15.5°C, vent 10 km/h...")
deactivate ollama

agent --> Utilisateur: "Météo pour Paris : 15.5°C,\nvent 10 km/h (direction 180°),\ncode météo 3."
deactivate agent
        
@enduml
#+end_src

[[file:./images/diagram.svg]]

** Functional Diagram
#+begin_src plantuml :file ./images/function.svg :results silent :exports none
@startuml

rectangle "Agent" as Agent {
  rectangle "Tool-Using\nAgent" as ToolAgent #LightGreen
  rectangle "Tools" as Tools #LightYellow

  ' Flèches internes
  ToolAgent -down[#DarkGreen]-> Tools : user request
}

 ' --- Blocs externes ---
rectangle "OLLAMA" as OLLAMA #LightBlue
rectangle "External APIs" as ExtLeft #Pink
rectangle "External APIs" as ExtRight #Pink

rectangle "Tool\nConfiguration" as ToolConf
rectangle "Direct Call" as DirectCall

 ' --- Positionnement approximatif ---
Agent -[hidden]right- OLLAMA
Agent -[hidden]right- ToolConf
Agent -[hidden]right- DirectCall
OLLAMA -[hidden]down- ToolConf
ToolConf -[hidden]down- DirectCall
DirectCall -[hidden]down- ExtRight
Tools -[hidden]down- ExtLeft
ExtLeft -[hidden]right- ExtRight

' --- Flots entre éléments ---
ToolAgent -right[#DarkGreen]-> OLLAMA : tool call
OLLAMA -left[#DarkBlue]-> ToolAgent : tool call
ToolConf ..right-> Tools
DirectCall ..right-> Tools

Tools -down[#Orange]-> ExtLeft : direct call
ExtRight -left-> ExtLeft : HTTP request

@enduml
#+end_src

[[./images/function.svg]]
